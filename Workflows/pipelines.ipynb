{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the breast cancer data\n",
    "dataset = datasets.load_breast_cancer()\n",
    "\n",
    "# Create X from the dataset's features\n",
    "X = dataset.data\n",
    "\n",
    "# Create y from the dataset's output\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Create a pca object\n",
    "pca = decomposition.PCA()\n",
    "\n",
    "# Create a logistic regression object with an L2 penalty\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "# Create a pipeline of three steps. First, standardize the data.\n",
    "# Second, tranform the data with PCA.\n",
    "# Third, train a logistic regression on the data.\n",
    "pipe = Pipeline(steps=[('sc', sc), \n",
    "                       ('pca', pca), \n",
    "                       ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of a sequence of integers from 1 to 30 (the number of features in X + 1)\n",
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "# Create a list of values of the regularization parameter\n",
    "C = np.logspace(-4, 4, 50)\n",
    "\n",
    "# Create a list of options for the regularization penalty\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create a dictionary of all the parameter options \n",
    "# Note has you can access the parameters of steps of a pipeline by using '__â€™\n",
    "parameters = dict(pca__n_components=n_components, \n",
    "                  logistic__C=C,\n",
    "                  logistic__penalty=penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conduct parameter optmization with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('sc',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('pca',\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=None,\n",
       "                                            random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('logistic',\n",
       "                                        LogisticRegression(C=1.0,\n",
       "                                                           class_weight=None,\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept=...\n",
       "       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n",
       "       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n",
       "       6.86648845e+03, 1.00000000e+04]),\n",
       "                         'logistic__penalty': ['l1', 'l2'],\n",
       "                         'pca__n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                               11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                                               19, 20, 21, 22, 23, 24, 25, 26,\n",
       "                                               27, 28, 29, 30]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a grid search object\n",
    "clf = GridSearchCV(pipe, parameters, cv = 5)\n",
    "\n",
    "# Fit the grid search\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 0.08685113737513521\n",
      "Best Number Of Components: 18\n"
     ]
    }
   ],
   "source": [
    "# View The Best Parameters\n",
    "print('Best Penalty:', clf.best_estimator_.get_params()['logistic__penalty'])\n",
    "print('Best C:', clf.best_estimator_.get_params()['logistic__C'])\n",
    "print('Best Number Of Components:', clf.best_estimator_.get_params()['pca__n_components'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use cross validation to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97894737, 0.97368421, 0.97354497])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search using 5-Fold cross validation\n",
    "cross_val_score(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
